{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelling.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lazysjb/camelyon16/blob/master/Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fFCVwD_Uhj6D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Modelling "
      ]
    },
    {
      "metadata": {
        "id": "0kQSxNyDhpKu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get Moduels and Data"
      ]
    },
    {
      "metadata": {
        "id": "vAPWhepvn180",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# install tensorflow \n",
        "#!pip install tensorflow\n",
        "#!pip install Keras --upgrade\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4iKAidrlfYSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe38759d-d1e5-48dc-da40-c53b940a5c5c"
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "import keras\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "w0Wku3kufenz",
        "colab_type": "code",
        "outputId": "0cf41363-efbe-4251-da26-e1d46c65f6aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4j5h8RLMgAtJ",
        "colab_type": "code",
        "outputId": "6988661d-6f51-4f94-c59e-cc912852bf04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "# working directory\n",
        "path = 'gdrive/My Drive/STUDY/Columbia/Term 2/Applied Deep Learning/Project/Final Training Data/shared_files'\n",
        "os.listdir(path)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_val_test_split.json',\n",
              " 'tumor_img_meta_info.json',\n",
              " 'zoom_5_60_60_partition.zip',\n",
              " 'zoom_5_60_60_partition',\n",
              " 'zoom_2_200_200_partition.zip',\n",
              " 'bounding_boxes',\n",
              " 'all_info_0.4_grayscale_tol_with_roi.json',\n",
              " 'zoom_1_256_256_partition.zip',\n",
              " 'zoom_1_256_256_partition_truncated.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "ToY97xsAgk5U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# unzip data folders to root dir\n",
        "zf = zipfile.ZipFile(os.path.join(path, 'zoom_5_60_60_partition.zip'))\n",
        "zf.extractall()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bIx7pQ2Ek_e1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "metadata": {
        "id": "zhg1hQw8lRkH",
        "colab_type": "code",
        "outputId": "2c0a35cb-9869-4786-ebf7-840e908360b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "# get metadata\n",
        "df_meta_greyscale = pd.read_json('zoom_5_60_60_partition/meta/all_info_0.4_grayscale_tol.json')\n",
        "df_meta_greyscale.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>img_id</th>\n",
              "      <th>include</th>\n",
              "      <th>label</th>\n",
              "      <th>non_gray_ratio</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tumor_slide_001_split_25_26.png</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tumor_slide_001_split_25_32.png</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tumor_slide_001_split_77_12.png</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.043333</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tumor_slide_001_split_31_47.png</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000556</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tumor_slide_001_split_79_17.png</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.031389</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         file_name  img_id  include  label  non_gray_ratio  \\\n",
              "0  tumor_slide_001_split_25_26.png       1        0      0        0.000000   \n",
              "1  tumor_slide_001_split_25_32.png       1        0      0        0.000000   \n",
              "2  tumor_slide_001_split_77_12.png       1        0      0        0.043333   \n",
              "3  tumor_slide_001_split_31_47.png       1        0      0        0.000556   \n",
              "4  tumor_slide_001_split_79_17.png       1        0      0        0.031389   \n",
              "\n",
              "  type  \n",
              "0  val  \n",
              "1  val  \n",
              "2  val  \n",
              "3  val  \n",
              "4  val  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "WWNNM35aOY95",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cast target as string (keras needs strings)\n",
        "%%capture\n",
        "df_meta_greyscale.loc[:, 'label'] = df_meta_greyscale.label.astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLIO57stpIH3",
        "colab_type": "code",
        "outputId": "e2f48952-6be5-4cb4-fd34-a2b25102caf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "# get patches with sufficient tissue\n",
        "df_train = df_meta_greyscale.loc[(df_meta_greyscale.include == 1) & (df_meta_greyscale['type'] == 'train'),:]\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>img_id</th>\n",
              "      <th>include</th>\n",
              "      <th>label</th>\n",
              "      <th>non_gray_ratio</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11567</th>\n",
              "      <td>tumor_slide_005_split_90_25.png</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.476667</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11582</th>\n",
              "      <td>tumor_slide_005_split_87_15.png</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11608</th>\n",
              "      <td>tumor_slide_005_split_89_10.png</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.805278</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11618</th>\n",
              "      <td>tumor_slide_005_split_89_11.png</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.978889</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11627</th>\n",
              "      <td>tumor_slide_005_split_80_21.png</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.822222</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             file_name  img_id  include label  non_gray_ratio  \\\n",
              "11567  tumor_slide_005_split_90_25.png       5        1     0        0.476667   \n",
              "11582  tumor_slide_005_split_87_15.png       5        1     0        0.966667   \n",
              "11608  tumor_slide_005_split_89_10.png       5        1     0        0.805278   \n",
              "11618  tumor_slide_005_split_89_11.png       5        1     0        0.978889   \n",
              "11627  tumor_slide_005_split_80_21.png       5        1     0        0.822222   \n",
              "\n",
              "        type  \n",
              "11567  train  \n",
              "11582  train  \n",
              "11608  train  \n",
              "11618  train  \n",
              "11627  train  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "EwX-WbvxsY87",
        "colab_type": "code",
        "outputId": "255f7c29-f66f-40c6-903b-2dee2a008601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "# get patches with sufficient tissue\n",
        "df_val = df_meta_greyscale.loc[(df_meta_greyscale.include == 1) & (df_meta_greyscale['type'] == 'val'),:]\n",
        "\n",
        "df_val.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>img_id</th>\n",
              "      <th>include</th>\n",
              "      <th>label</th>\n",
              "      <th>non_gray_ratio</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tumor_slide_001_split_70_33.png</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.975833</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tumor_slide_001_split_70_27.png</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.985556</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>tumor_slide_001_split_0_46.png</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.666944</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>tumor_slide_001_split_60_22.png</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.960278</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>tumor_slide_001_split_41_13.png</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          file_name  img_id  include label  non_gray_ratio  \\\n",
              "5   tumor_slide_001_split_70_33.png       1        1     0        0.975833   \n",
              "9   tumor_slide_001_split_70_27.png       1        1     0        0.985556   \n",
              "28   tumor_slide_001_split_0_46.png       1        1     0        0.666944   \n",
              "45  tumor_slide_001_split_60_22.png       1        1     0        0.960278   \n",
              "52  tumor_slide_001_split_41_13.png       1        1     0        0.997500   \n",
              "\n",
              "   type  \n",
              "5   val  \n",
              "9   val  \n",
              "28  val  \n",
              "45  val  \n",
              "52  val  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "lQ4Y9BExPpN_",
        "colab_type": "code",
        "outputId": "7f24d093-12ec-4c9a-b14b-a173fdb1b9e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "# get patches with sufficient tissue\n",
        "df_test = df_meta_greyscale.loc[(df_meta_greyscale.include == 1) & (df_meta_greyscale['type'] == 'test'),:]\n",
        "\n",
        "df_test.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>img_id</th>\n",
              "      <th>include</th>\n",
              "      <th>label</th>\n",
              "      <th>non_gray_ratio</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5777</th>\n",
              "      <td>tumor_slide_002_split_52_16.png</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.422500</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5783</th>\n",
              "      <td>tumor_slide_002_split_55_23.png</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5803</th>\n",
              "      <td>tumor_slide_002_split_63_36.png</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.886389</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5854</th>\n",
              "      <td>tumor_slide_002_split_61_33.png</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.938333</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5903</th>\n",
              "      <td>tumor_slide_002_split_50_13.png</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.949444</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            file_name  img_id  include label  non_gray_ratio  \\\n",
              "5777  tumor_slide_002_split_52_16.png       2        1     0        0.422500   \n",
              "5783  tumor_slide_002_split_55_23.png       2        1     0        0.912500   \n",
              "5803  tumor_slide_002_split_63_36.png       2        1     0        0.886389   \n",
              "5854  tumor_slide_002_split_61_33.png       2        1     0        0.938333   \n",
              "5903  tumor_slide_002_split_50_13.png       2        1     0        0.949444   \n",
              "\n",
              "      type  \n",
              "5777  test  \n",
              "5783  test  \n",
              "5803  test  \n",
              "5854  test  \n",
              "5903  test  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "YFfNpxAF9IDC",
        "colab_type": "code",
        "outputId": "837674ac-2378-448d-d867-fd813cfcdb82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# downsample df \n",
        "df_train['label'].value_counts()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3967\n",
              "1     695\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "KxUi4ESC9fGp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_down = pd.concat([df_train[df_train['label'] == '0'].sample(1000), df_train[df_train['label'] == '1']], axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DJntrC93Dqwl",
        "colab_type": "code",
        "outputId": "908f7ba5-b8ae-4263-abc0-59759c0718d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "df_down.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>img_id</th>\n",
              "      <th>include</th>\n",
              "      <th>label</th>\n",
              "      <th>non_gray_ratio</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49774</th>\n",
              "      <td>tumor_slide_035_split_54_16.png</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.576667</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75686</th>\n",
              "      <td>tumor_slide_084_split_32_13.png</td>\n",
              "      <td>84</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.641944</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58942</th>\n",
              "      <td>tumor_slide_059_split_79_29.png</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.966111</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78067</th>\n",
              "      <td>tumor_slide_094_split_31_20.png</td>\n",
              "      <td>94</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.996389</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69446</th>\n",
              "      <td>tumor_slide_075_split_11_37.png</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.805278</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             file_name  img_id  include label  non_gray_ratio  \\\n",
              "49774  tumor_slide_035_split_54_16.png      35        1     0        0.576667   \n",
              "75686  tumor_slide_084_split_32_13.png      84        1     0        0.641944   \n",
              "58942  tumor_slide_059_split_79_29.png      59        1     0        0.966111   \n",
              "78067  tumor_slide_094_split_31_20.png      94        1     0        0.996389   \n",
              "69446  tumor_slide_075_split_11_37.png      75        1     0        0.805278   \n",
              "\n",
              "        type  \n",
              "49774  train  \n",
              "75686  train  \n",
              "58942  train  \n",
              "78067  train  \n",
              "69446  train  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "hbivJH-_kFcZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a212baa7-fcf1-47ce-b252-24cfdfb5a710"
      },
      "cell_type": "code",
      "source": [
        "df_down.label.value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1000\n",
              "1     695\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "uwad5EJaGEQD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_up = pd.concat([df_train, df_train[df_train['label'] == '1'].sample(3500, replace=True)], axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-T2HTotGMZE",
        "colab_type": "code",
        "outputId": "077a9d6c-f4ac-4a9d-d762-cdf78bf41634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "df_up.label.value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4195\n",
              "0    3967\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "MrzA5-KhmUq4",
        "colab_type": "code",
        "outputId": "1f27def8-8aaa-4193-8aa5-c08cbc5e716a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# specify image data generator with augmentation\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                         rotation_range=180,\n",
        "                                                         horizontal_flip=True,\n",
        "                                                         vertical_flip = True)\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# read data from the train directory\n",
        "train_generator = datagen.flow_from_dataframe(dataframe = df_up, \n",
        "                                              directory = 'zoom_5_60_60_partition/train/slide',\n",
        "                                              x_col = 'file_name', \n",
        "                                              y_col='label',\n",
        "                                              class_mode='binary', \n",
        "                                              target_size=(60,60), \n",
        "                                              batch_size=32,\n",
        "                                              drop_duplicates=False)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8162 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xtcfsYoBiMg7",
        "colab_type": "code",
        "outputId": "26e025d4-55c8-46b4-fc33-248395bcebb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_generator)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "VQb6Vw_eP8DF",
        "colab_type": "code",
        "outputId": "4ebabe94-b40b-433b-abdf-04ec55d5d6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# specify image data generator with augmentation\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# read data from the train directory\n",
        "val_generator = datagen.flow_from_dataframe(dataframe = df_val, \n",
        "                                              directory = 'zoom_5_60_60_partition/val/slide',\n",
        "                                              x_col = 'file_name', \n",
        "                                              y_col='label',\n",
        "                                              class_mode='binary', \n",
        "                                              target_size=(60,60), \n",
        "                                              batch_size=32)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1283 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2y4r0qoAjBlC",
        "colab_type": "code",
        "outputId": "189bd253-bd17-405b-955c-e89543a14b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(val_generator)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "JN3UZpAyJ4FH",
        "colab_type": "code",
        "outputId": "aca8b5ed-b015-4216-ea9f-b27e59689c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "cell_type": "code",
      "source": [
        "# plot augmented images\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(10,10))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.grid(False)\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "augmented_images = [train_generator[0][0][0] for i in range(5)]\n",
        "\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAACOCAYAAAAsNf4uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyJIkSVLlH1CBKDkmjqnhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9cdGLMMdQ9Ce",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  Baseline model"
      ]
    },
    {
      "metadata": {
        "id": "T83cXCxGJuZl",
        "colab_type": "code",
        "outputId": "42284948-ed6f-4516-a421-f974934b38b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "# specify model architecture\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(60, 60, 3)))\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "#model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "#model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "#model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V8TmDpGWeM06",
        "colab_type": "code",
        "outputId": "aba943e2-ac65-4f61-938d-2e73b0def51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print model architecture\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 58, 58, 64)        1792      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 56, 56, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 54, 54, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 27, 27, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 186624)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               23888000  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 24,258,945\n",
            "Trainable params: 24,258,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B3EGiVZjLYCU",
        "colab_type": "code",
        "outputId": "ce9e3200-e2f2-4ed8-99ef-0f725ee12e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "history_1 = model.fit_generator(train_generator,\n",
        "                   epochs = EPOCHS,\n",
        "                   validation_data = val_generator,\n",
        "                   verbose=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "41/41 [==============================] - 1s 31ms/step - loss: 0.5171 - acc: 0.7553\n",
            "256/256 [==============================] - 22s 84ms/step - loss: 0.6145 - acc: 0.6971 - val_loss: 0.5171 - val_acc: 0.7553\n",
            "Epoch 2/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4810 - acc: 0.8480\n",
            "256/256 [==============================] - 18s 69ms/step - loss: 0.4781 - acc: 0.7623 - val_loss: 0.4810 - val_acc: 0.8480\n",
            "Epoch 3/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.3819 - acc: 0.8807\n",
            "256/256 [==============================] - 19s 73ms/step - loss: 0.4573 - acc: 0.7719 - val_loss: 0.3819 - val_acc: 0.8807\n",
            "Epoch 4/20\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.3738 - acc: 0.8807\n",
            "256/256 [==============================] - 18s 69ms/step - loss: 0.4522 - acc: 0.7757 - val_loss: 0.3738 - val_acc: 0.8807\n",
            "Epoch 5/20\n",
            "41/41 [==============================] - 1s 32ms/step - loss: 0.4512 - acc: 0.8807\n",
            "256/256 [==============================] - 18s 70ms/step - loss: 0.4263 - acc: 0.7931 - val_loss: 0.4512 - val_acc: 0.8807\n",
            "Epoch 6/20\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.4895 - acc: 0.8613\n",
            "256/256 [==============================] - 18s 70ms/step - loss: 0.4276 - acc: 0.7928 - val_loss: 0.4895 - val_acc: 0.8613\n",
            "Epoch 7/20\n",
            "41/41 [==============================] - 1s 32ms/step - loss: 0.4407 - acc: 0.8807\n",
            "256/256 [==============================] - 19s 74ms/step - loss: 0.3987 - acc: 0.8036 - val_loss: 0.4407 - val_acc: 0.8807\n",
            "Epoch 8/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4621 - acc: 0.8675\n",
            "256/256 [==============================] - 18s 68ms/step - loss: 0.3960 - acc: 0.8073 - val_loss: 0.4621 - val_acc: 0.8675\n",
            "Epoch 9/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4952 - acc: 0.8558\n",
            "256/256 [==============================] - 18s 68ms/step - loss: 0.3722 - acc: 0.8223 - val_loss: 0.4952 - val_acc: 0.8558\n",
            "Epoch 10/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.3287 - acc: 0.8815\n",
            "256/256 [==============================] - 18s 69ms/step - loss: 0.3672 - acc: 0.8290 - val_loss: 0.3287 - val_acc: 0.8815\n",
            "Epoch 11/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4313 - acc: 0.8558\n",
            "256/256 [==============================] - 18s 69ms/step - loss: 0.3397 - acc: 0.8437 - val_loss: 0.4313 - val_acc: 0.8558\n",
            "Epoch 12/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.5247 - acc: 0.7911\n",
            "256/256 [==============================] - 19s 73ms/step - loss: 0.3151 - acc: 0.8595 - val_loss: 0.5247 - val_acc: 0.7911\n",
            "Epoch 13/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.6813 - acc: 0.7514\n",
            "256/256 [==============================] - 18s 69ms/step - loss: 0.3357 - acc: 0.8464 - val_loss: 0.6813 - val_acc: 0.7514\n",
            "Epoch 14/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.8254 - acc: 0.6290\n",
            "256/256 [==============================] - 18s 69ms/step - loss: 0.3033 - acc: 0.8614 - val_loss: 0.8254 - val_acc: 0.6290\n",
            "Epoch 15/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.3742 - acc: 0.8620\n",
            "256/256 [==============================] - 17s 68ms/step - loss: 0.3098 - acc: 0.8601 - val_loss: 0.3742 - val_acc: 0.8620\n",
            "Epoch 16/20\n",
            "41/41 [==============================] - 1s 32ms/step - loss: 0.8226 - acc: 0.6111\n",
            "256/256 [==============================] - 19s 73ms/step - loss: 0.3033 - acc: 0.8619 - val_loss: 0.8226 - val_acc: 0.6111\n",
            "Epoch 17/20\n",
            "41/41 [==============================] - 1s 33ms/step - loss: 0.6505 - acc: 0.7303\n",
            "256/256 [==============================] - 19s 72ms/step - loss: 0.3000 - acc: 0.8631 - val_loss: 0.6505 - val_acc: 0.7303\n",
            "Epoch 18/20\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.6991 - acc: 0.7178\n",
            "256/256 [==============================] - 18s 71ms/step - loss: 0.3027 - acc: 0.8649 - val_loss: 0.6991 - val_acc: 0.7178\n",
            "Epoch 19/20\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.5129 - acc: 0.8324\n",
            "256/256 [==============================] - 18s 68ms/step - loss: 0.2845 - acc: 0.8717 - val_loss: 0.5129 - val_acc: 0.8324\n",
            "Epoch 20/20\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.5832 - acc: 0.7506\n",
            "256/256 [==============================] - 18s 69ms/step - loss: 0.2774 - acc: 0.8764 - val_loss: 0.5832 - val_acc: 0.7506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y-3ZsSabkHY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adjusted class weights model"
      ]
    },
    {
      "metadata": {
        "id": "EKuuoJG-Y_FU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "03bc64c9-454b-4574-facc-5a1d6154e148"
      },
      "cell_type": "code",
      "source": [
        "# try again with balanced class weights\n",
        "import sklearn\n",
        "import numpy as np\n",
        "\n",
        "y_train = df_train['label']\n",
        "\n",
        "class_weights = sklearn.utils.class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n",
        "\n",
        "class_weights"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.58759768, 3.35395683])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "oPh0egB2jeCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7049730f-ad30-4ab8-d9ad-11ab5a31e2ad"
      },
      "cell_type": "code",
      "source": [
        "# create class weights dictionary\n",
        "cw = dict(zip([0,1], class_weights))\n",
        "# doesnt work for some reason \n",
        "cw"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.587597680867154, 1: 3.353956834532374}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "762pzh9RmfJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# specify model architecture\n",
        "model_2 = tf.keras.Sequential()\n",
        "\n",
        "model_2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(60, 60, 3)))\n",
        "model_2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model_2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model_2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model_2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model_2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model_2.add(tf.keras.layers.Flatten())\n",
        "model_2.add(tf.keras.layers.Flatten(input_shape = (60, 60, 3)))\n",
        "model_2.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model_2.add(tf.keras.layers.Dense(128, activation='tanh'))\n",
        "model_2.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wGAR-3M-er-L",
        "colab_type": "code",
        "outputId": "b5e15d3c-509a-4c8f-9e93-9be52741f273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "cell_type": "code",
      "source": [
        "# recompile model\n",
        "model_2.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 58, 58, 64)        1792      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 56, 56, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               2359552   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,505,153\n",
            "Trainable params: 2,505,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mVrZmaTWde1G",
        "colab_type": "code",
        "outputId": "7de0a5cc-7ab4-42e7-d874-8418b497e6cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2090
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 40\n",
        "\n",
        "history_2 = model_2.fit_generator(train_generator,\n",
        "                   epochs = EPOCHS,\n",
        "                   validation_data = val_generator,\n",
        "                   class_weight = class_weights,\n",
        "                   shuffle=True)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.4047 - acc: 0.8807\n",
            "256/256 [==============================] - 16s 61ms/step - loss: 0.6417 - acc: 0.6007 - val_loss: 0.4047 - val_acc: 0.8807\n",
            "Epoch 2/40\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.3819 - acc: 0.8807\n",
            "256/256 [==============================] - 16s 62ms/step - loss: 0.4836 - acc: 0.7635 - val_loss: 0.3819 - val_acc: 0.8807\n",
            "Epoch 3/40\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.4504 - acc: 0.8691\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.4575 - acc: 0.7765 - val_loss: 0.4504 - val_acc: 0.8691\n",
            "Epoch 4/40\n",
            "41/41 [==============================] - 1s 31ms/step - loss: 0.3667 - acc: 0.8807\n",
            "256/256 [==============================] - 16s 63ms/step - loss: 0.4310 - acc: 0.7904 - val_loss: 0.3667 - val_acc: 0.8807\n",
            "Epoch 5/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.3291 - acc: 0.8807\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.4260 - acc: 0.7937 - val_loss: 0.3291 - val_acc: 0.8807\n",
            "Epoch 6/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.3884 - acc: 0.8714\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.4070 - acc: 0.8051 - val_loss: 0.3884 - val_acc: 0.8714\n",
            "Epoch 7/40\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 0.3195 - acc: 0.8807\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.4011 - acc: 0.8127 - val_loss: 0.3195 - val_acc: 0.8807\n",
            "Epoch 8/40\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.4832 - acc: 0.7763\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.3818 - acc: 0.8285 - val_loss: 0.4832 - val_acc: 0.7763\n",
            "Epoch 9/40\n",
            "41/41 [==============================] - 1s 32ms/step - loss: 0.3196 - acc: 0.8769\n",
            "256/256 [==============================] - 15s 61ms/step - loss: 0.3877 - acc: 0.8246 - val_loss: 0.3196 - val_acc: 0.8769\n",
            "Epoch 10/40\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.4630 - acc: 0.7903\n",
            "256/256 [==============================] - 16s 63ms/step - loss: 0.4084 - acc: 0.8076 - val_loss: 0.4630 - val_acc: 0.7903\n",
            "Epoch 11/40\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 0.6134 - acc: 0.6984\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.3761 - acc: 0.8292 - val_loss: 0.6134 - val_acc: 0.6984\n",
            "Epoch 12/40\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.6855 - acc: 0.6726\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.3589 - acc: 0.8396 - val_loss: 0.6855 - val_acc: 0.6726\n",
            "Epoch 13/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.7504 - acc: 0.5900\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.3485 - acc: 0.8438 - val_loss: 0.7504 - val_acc: 0.5900\n",
            "Epoch 14/40\n",
            "41/41 [==============================] - 1s 31ms/step - loss: 0.5005 - acc: 0.7849\n",
            "256/256 [==============================] - 16s 62ms/step - loss: 0.3298 - acc: 0.8488 - val_loss: 0.5005 - val_acc: 0.7849\n",
            "Epoch 15/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.5224 - acc: 0.7857\n",
            "256/256 [==============================] - 16s 64ms/step - loss: 0.3292 - acc: 0.8525 - val_loss: 0.5224 - val_acc: 0.7857\n",
            "Epoch 16/40\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 0.4384 - acc: 0.8301\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.3209 - acc: 0.8547 - val_loss: 0.4384 - val_acc: 0.8301\n",
            "Epoch 17/40\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4815 - acc: 0.8106\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.3103 - acc: 0.8609 - val_loss: 0.4815 - val_acc: 0.8106\n",
            "Epoch 18/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 1.3411 - acc: 0.4770\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.3150 - acc: 0.8603 - val_loss: 1.3411 - val_acc: 0.4770\n",
            "Epoch 19/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.5112 - acc: 0.8176\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.3156 - acc: 0.8603 - val_loss: 0.5112 - val_acc: 0.8176\n",
            "Epoch 20/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.3449 - acc: 0.8652\n",
            "256/256 [==============================] - 16s 64ms/step - loss: 0.2955 - acc: 0.8647 - val_loss: 0.3449 - val_acc: 0.8652\n",
            "Epoch 21/40\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.4407 - acc: 0.8145\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.3115 - acc: 0.8618 - val_loss: 0.4407 - val_acc: 0.8145\n",
            "Epoch 22/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.9402 - acc: 0.6500\n",
            "256/256 [==============================] - 16s 62ms/step - loss: 0.2760 - acc: 0.8770 - val_loss: 0.9402 - val_acc: 0.6500\n",
            "Epoch 23/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.3859 - acc: 0.8449\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.2986 - acc: 0.8684 - val_loss: 0.3859 - val_acc: 0.8449\n",
            "Epoch 24/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.3481 - acc: 0.8644\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.2780 - acc: 0.8749 - val_loss: 0.3481 - val_acc: 0.8644\n",
            "Epoch 25/40\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.5696 - acc: 0.7888\n",
            "256/256 [==============================] - 16s 63ms/step - loss: 0.2849 - acc: 0.8680 - val_loss: 0.5696 - val_acc: 0.7888\n",
            "Epoch 26/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.3559 - acc: 0.8652\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.2755 - acc: 0.8763 - val_loss: 0.3559 - val_acc: 0.8652\n",
            "Epoch 27/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.4198 - acc: 0.8379\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.2742 - acc: 0.8760 - val_loss: 0.4198 - val_acc: 0.8379\n",
            "Epoch 28/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.8967 - acc: 0.6867\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.2574 - acc: 0.8851 - val_loss: 0.8967 - val_acc: 0.6867\n",
            "Epoch 29/40\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.5214 - acc: 0.7794\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.2630 - acc: 0.8840 - val_loss: 0.5214 - val_acc: 0.7794\n",
            "Epoch 30/40\n",
            "41/41 [==============================] - 1s 31ms/step - loss: 1.1089 - acc: 0.6150\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.2573 - acc: 0.8843 - val_loss: 1.1089 - val_acc: 0.6150\n",
            "Epoch 31/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.4701 - acc: 0.8340\n",
            "256/256 [==============================] - 16s 62ms/step - loss: 0.2562 - acc: 0.8868 - val_loss: 0.4701 - val_acc: 0.8340\n",
            "Epoch 32/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.8197 - acc: 0.7132\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.2501 - acc: 0.8840 - val_loss: 0.8197 - val_acc: 0.7132\n",
            "Epoch 33/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.8583 - acc: 0.7233\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.2439 - acc: 0.8901 - val_loss: 0.8583 - val_acc: 0.7233\n",
            "Epoch 34/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.6020 - acc: 0.8036\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.2511 - acc: 0.8880 - val_loss: 0.6020 - val_acc: 0.8036\n",
            "Epoch 35/40\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.8077 - acc: 0.6773\n",
            "256/256 [==============================] - 17s 65ms/step - loss: 0.2478 - acc: 0.8885 - val_loss: 0.8077 - val_acc: 0.6773\n",
            "Epoch 36/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.7168 - acc: 0.7264\n",
            "256/256 [==============================] - 16s 63ms/step - loss: 0.2336 - acc: 0.8962 - val_loss: 0.7168 - val_acc: 0.7264\n",
            "Epoch 37/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.4491 - acc: 0.8402\n",
            "256/256 [==============================] - 15s 59ms/step - loss: 0.2372 - acc: 0.8930 - val_loss: 0.4491 - val_acc: 0.8402\n",
            "Epoch 38/40\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 0.5667 - acc: 0.7662\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.2282 - acc: 0.8998 - val_loss: 0.5667 - val_acc: 0.7662\n",
            "Epoch 39/40\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 0.5672 - acc: 0.7708\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.2274 - acc: 0.8982 - val_loss: 0.5672 - val_acc: 0.7708\n",
            "Epoch 40/40\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.7063 - acc: 0.7896\n",
            "256/256 [==============================] - 15s 58ms/step - loss: 0.2212 - acc: 0.8989 - val_loss: 0.7063 - val_acc: 0.7896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c3IoQaWoPnKy",
        "colab_type": "code",
        "outputId": "b67d08c7-a165-4758-92be-d7d6f28aa048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "cell_type": "code",
      "source": [
        "model.predict(val_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2554441 ],\n",
              "       [0.90633047],\n",
              "       [0.2586465 ],\n",
              "       ...,\n",
              "       [0.09441949],\n",
              "       [0.0263592 ],\n",
              "       [0.3309168 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "W4fYbpnfP6Jo",
        "colab_type": "code",
        "outputId": "e7c8a3b6-dfb3-4afe-8412-c62c984a419a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "y_val = df_val['label']\n",
        "y_val.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.880748\n",
              "1    0.119252\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "imnc8jJGchfz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use Transfer Learning"
      ]
    },
    {
      "metadata": {
        "id": "v0Ah7FAzqQop",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7HhL28WS8hd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv_base_1 = VGG16(weights='imagenet',\n",
        "                    include_top=False, \n",
        "                    input_shape=(60, 60, 3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nXFeFJH3p7dY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "outputId": "e164bcac-46f3-4f5c-e354-205597a0575e"
      },
      "cell_type": "code",
      "source": [
        "conv_base_1.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 60, 60, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 60, 60, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 60, 60, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 30, 30, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 30, 30, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 15, 15, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 15, 15, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 15, 15, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aGBUClEhoeRF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# instantiate model\n",
        "model_1 = tf.keras.models.Sequential()\n",
        "\n",
        "model_1.add(conv_base_1)\n",
        "model_1.add(tf.keras.layers.Flatten())\n",
        "model_1.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "conv_base_1.trainable = False\n",
        "\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FOuCylvyowVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "86d87b36-b71c-4791-a6f9-c6dc9b6e3c4b"
      },
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 15,108,929\n",
            "Trainable params: 394,241\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AqgXczp0v9vQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "38ca8f73-f43b-48aa-b464-21e429388984"
      },
      "cell_type": "code",
      "source": [
        "model_1.fit_generator(train_generator,\n",
        "                   epochs = 20,\n",
        "                   validation_data = val_generator,\n",
        "                   verbose=1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.5900 - acc: 0.6399\n",
            "256/256 [==============================] - 20s 76ms/step - loss: 0.5748 - acc: 0.6925 - val_loss: 0.5900 - val_acc: 0.6399\n",
            "Epoch 2/20\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.3532 - acc: 0.8683\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.5027 - acc: 0.7458 - val_loss: 0.3532 - val_acc: 0.8683\n",
            "Epoch 3/20\n",
            "41/41 [==============================] - 1s 34ms/step - loss: 0.5914 - acc: 0.6921\n",
            "256/256 [==============================] - 17s 65ms/step - loss: 0.4770 - acc: 0.7585 - val_loss: 0.5914 - val_acc: 0.6921\n",
            "Epoch 4/20\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.4964 - acc: 0.7607\n",
            "256/256 [==============================] - 16s 61ms/step - loss: 0.4774 - acc: 0.7618 - val_loss: 0.4964 - val_acc: 0.7607\n",
            "Epoch 5/20\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.4580 - acc: 0.7903\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.4674 - acc: 0.7634 - val_loss: 0.4580 - val_acc: 0.7903\n",
            "Epoch 6/20\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.3899 - acc: 0.8527\n",
            "256/256 [==============================] - 16s 61ms/step - loss: 0.4471 - acc: 0.7771 - val_loss: 0.3899 - val_acc: 0.8527\n",
            "Epoch 7/20\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.3921 - acc: 0.8581\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.4418 - acc: 0.7835 - val_loss: 0.3921 - val_acc: 0.8581\n",
            "Epoch 8/20\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.4709 - acc: 0.7896\n",
            "256/256 [==============================] - 16s 63ms/step - loss: 0.4321 - acc: 0.7830 - val_loss: 0.4709 - val_acc: 0.7896\n",
            "Epoch 9/20\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4081 - acc: 0.8504\n",
            "256/256 [==============================] - 17s 66ms/step - loss: 0.4263 - acc: 0.7839 - val_loss: 0.4081 - val_acc: 0.8504\n",
            "Epoch 10/20\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.3832 - acc: 0.8745\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.4184 - acc: 0.7937 - val_loss: 0.3832 - val_acc: 0.8745\n",
            "Epoch 11/20\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.4585 - acc: 0.7872\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.4219 - acc: 0.7933 - val_loss: 0.4585 - val_acc: 0.7872\n",
            "Epoch 12/20\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4147 - acc: 0.8262\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.4154 - acc: 0.7933 - val_loss: 0.4147 - val_acc: 0.8262\n",
            "Epoch 13/20\n",
            "41/41 [==============================] - 1s 34ms/step - loss: 0.4097 - acc: 0.8285\n",
            "256/256 [==============================] - 16s 64ms/step - loss: 0.4110 - acc: 0.7980 - val_loss: 0.4097 - val_acc: 0.8285\n",
            "Epoch 14/20\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.4007 - acc: 0.8504\n",
            "256/256 [==============================] - 16s 62ms/step - loss: 0.4057 - acc: 0.8013 - val_loss: 0.4007 - val_acc: 0.8504\n",
            "Epoch 15/20\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4266 - acc: 0.8137\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.4005 - acc: 0.8013 - val_loss: 0.4266 - val_acc: 0.8137\n",
            "Epoch 16/20\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.3826 - acc: 0.8706\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.4039 - acc: 0.7983 - val_loss: 0.3826 - val_acc: 0.8706\n",
            "Epoch 17/20\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.4045 - acc: 0.8613\n",
            "256/256 [==============================] - 16s 61ms/step - loss: 0.3892 - acc: 0.8111 - val_loss: 0.4045 - val_acc: 0.8613\n",
            "Epoch 18/20\n",
            "41/41 [==============================] - 1s 34ms/step - loss: 0.4177 - acc: 0.8441\n",
            "256/256 [==============================] - 16s 62ms/step - loss: 0.3956 - acc: 0.8034 - val_loss: 0.4177 - val_acc: 0.8441\n",
            "Epoch 19/20\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4157 - acc: 0.8589\n",
            "256/256 [==============================] - 16s 64ms/step - loss: 0.3961 - acc: 0.8054 - val_loss: 0.4157 - val_acc: 0.8589\n",
            "Epoch 20/20\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4285 - acc: 0.8293\n",
            "256/256 [==============================] - 15s 60ms/step - loss: 0.3918 - acc: 0.8070 - val_loss: 0.4285 - val_acc: 0.8293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5158b55a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "h51wu8qa4crA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Grid search model"
      ]
    },
    {
      "metadata": {
        "id": "NitMEGDZd3jK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_model(units_1, units_2, reg_str_1, reg_str_2):\n",
        "  \n",
        "  conv_base_1 = VGG16(weights='imagenet',\n",
        "                    include_top=False, \n",
        "                    input_shape=(60, 60, 3))\n",
        "  \n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  model_1.add(conv_base_1)\n",
        "  \n",
        "  model_1.add(tf.keras.layers.Flatten())\n",
        "  \n",
        "  model_1.add(tf.keras.layers.Dense(units_1, activation='relu',\n",
        "                                   kernel_regularizer=keras.regularizers.l2(l= reg_str_1)))\n",
        "  \n",
        "  model_1.add(tf.keras.layers.Dense(units_2, activation='relu',\n",
        "                                   kernel_regularizer=keras.regularizers.l2(l= reg_str_2)))\n",
        "  \n",
        "  model_1.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  conv_base_1.trainable = False\n",
        "\n",
        "  model.compile(optimizer = 'adam', \n",
        "                  loss='binary_crossentropy',\n",
        "                 metrics=['acc'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "131veQyP8ddo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MtK5D4Y8j8zF",
        "colab_type": "code",
        "outputId": "bc18dff0-83df-4868-931a-39e92bfbee40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "cell_type": "code",
      "source": [
        "clf = KerasClassifier(make_model)\n",
        "\n",
        "param_grid = {'epochs': [30],\n",
        "              'units_1': [128,256], \n",
        "              'units_2': [64,128],\n",
        "              'reg_str_1': np.logspace(-3,3,3),\n",
        "              'reg_str_2': np.logspace(-3,3,3)\n",
        "             }\n",
        "\n",
        "grid = GridSearchCV(clf, param_grid=param_grid, cv= StratifiedShuffleSplit(1))\n",
        "grid.fit(train_generator)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-a3bade673d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1771\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \"\"\"\n\u001b[0;32m-> 1773\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 142\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Singleton array array(None, dtype=object) cannot be considered a valid collection."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bD4W-DcBiC6L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##More complex convolutional model"
      ]
    },
    {
      "metadata": {
        "id": "iBNno4RtiKu_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_conv_1 = tf.keras.Sequential([\n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), input_shape = (60,60,3)),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(),   \n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(), \n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)), \n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(), \n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(), \n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),  \n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(), \n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(), \n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),  \n",
        "    \n",
        "    tf.keras.layers.Flatten(), \n",
        "    \n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate = 0.3),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate = 0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate = 0.15),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "model_conv_1.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P1EmyxrckZkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1140
        },
        "outputId": "e9fc4805-fc91-4715-bc2a-4eca9908096d"
      },
      "cell_type": "code",
      "source": [
        "model_conv_1.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 58, 58, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 58, 58, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_6 (Ba (None, 58, 58, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 56, 56, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_7 (Ba (None, 56, 56, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 26, 26, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_8 (Ba (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_9 (Ba (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 10, 10, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_10 (B (None, 10, 10, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_11 (B (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 138,401\n",
            "Trainable params: 138,017\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n3gAMHQZlK-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5199
        },
        "outputId": "bd037abe-4b76-4ad1-eb5b-df0f6831f02f"
      },
      "cell_type": "code",
      "source": [
        "history_conv_1 = model_conv_1.fit_generator(train_generator, validation_data= val_generator, epochs = 100)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9887 - acc: 0.8714\n",
            "256/256 [==============================] - 9s 34ms/step - loss: 0.0225 - acc: 0.9936 - val_loss: 1.9887 - val_acc: 0.8714\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7008 - acc: 0.8122\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0230 - acc: 0.9920 - val_loss: 1.7008 - val_acc: 0.8122\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 1s 22ms/step - loss: 1.8443 - acc: 0.8730\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0202 - acc: 0.9933 - val_loss: 1.8443 - val_acc: 0.8730\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 1s 24ms/step - loss: 1.8125 - acc: 0.8769\n",
            "256/256 [==============================] - 10s 38ms/step - loss: 0.0337 - acc: 0.9896 - val_loss: 1.8125 - val_acc: 0.8769\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 0.8971 - acc: 0.8145\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0356 - acc: 0.9907 - val_loss: 0.8971 - val_acc: 0.8145\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0137 - acc: 0.8800\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0436 - acc: 0.9960 - val_loss: 2.0137 - val_acc: 0.8800\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9949 - acc: 0.8745\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0171 - acc: 0.9945 - val_loss: 1.9949 - val_acc: 0.8745\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.6057 - acc: 0.8667\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0203 - acc: 0.9944 - val_loss: 1.6057 - val_acc: 0.8667\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7229 - acc: 0.8683\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0130 - acc: 0.9957 - val_loss: 1.7229 - val_acc: 0.8683\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8807 - acc: 0.8628\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0105 - acc: 0.9968 - val_loss: 1.8807 - val_acc: 0.8628\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9607 - acc: 0.8737\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0175 - acc: 0.9938 - val_loss: 1.9607 - val_acc: 0.8737\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8710 - acc: 0.8426\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 1.8710 - val_acc: 0.8426\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.6007 - acc: 0.8706\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0856 - acc: 0.9771 - val_loss: 1.6007 - val_acc: 0.8706\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0123 - acc: 0.8698\n",
            "256/256 [==============================] - 9s 35ms/step - loss: 0.0160 - acc: 0.9946 - val_loss: 2.0123 - val_acc: 0.8698\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 1s 23ms/step - loss: 1.3475 - acc: 0.8200\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.1173 - acc: 0.9707 - val_loss: 1.3475 - val_acc: 0.8200\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9927 - acc: 0.8675\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0148 - acc: 0.9955 - val_loss: 1.9927 - val_acc: 0.8675\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9049 - acc: 0.8394\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0126 - acc: 0.9956 - val_loss: 1.9049 - val_acc: 0.8394\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7470 - acc: 0.8691\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0110 - acc: 0.9962 - val_loss: 1.7470 - val_acc: 0.8691\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9676 - acc: 0.8745\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0370 - acc: 0.9902 - val_loss: 1.9676 - val_acc: 0.8745\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.4484 - acc: 0.8753\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0281 - acc: 0.9942 - val_loss: 1.4484 - val_acc: 0.8753\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.5514 - acc: 0.8792\n",
            "256/256 [==============================] - 10s 37ms/step - loss: 0.0489 - acc: 0.9808 - val_loss: 1.5514 - val_acc: 0.8792\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.3055 - acc: 0.8550\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0134 - acc: 0.9963 - val_loss: 1.3055 - val_acc: 0.8550\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.4916 - acc: 0.8698\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0849 - acc: 0.9793 - val_loss: 1.4916 - val_acc: 0.8698\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 1s 22ms/step - loss: 1.9813 - acc: 0.8636\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0100 - acc: 0.9972 - val_loss: 1.9813 - val_acc: 0.8636\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.5801 - acc: 0.8184\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0208 - acc: 0.9938 - val_loss: 1.5801 - val_acc: 0.8184\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0739 - acc: 0.8691\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0071 - acc: 0.9978 - val_loss: 2.0739 - val_acc: 0.8691\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7499 - acc: 0.8667\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0349 - acc: 0.9929 - val_loss: 1.7499 - val_acc: 0.8667\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7695 - acc: 0.8262\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0142 - acc: 0.9949 - val_loss: 1.7695 - val_acc: 0.8262\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.5460 - acc: 0.8667\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0329 - acc: 0.9928 - val_loss: 1.5460 - val_acc: 0.8667\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.1082 - acc: 0.8885\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0150 - acc: 0.9961 - val_loss: 1.1082 - val_acc: 0.8885\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8134 - acc: 0.8379\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0296 - acc: 0.9930 - val_loss: 1.8134 - val_acc: 0.8379\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.2828 - acc: 0.8613\n",
            "256/256 [==============================] - 10s 38ms/step - loss: 0.0191 - acc: 0.9953 - val_loss: 1.2828 - val_acc: 0.8613\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.6783 - acc: 0.8628\n",
            "256/256 [==============================] - 9s 33ms/step - loss: 0.0272 - acc: 0.9933 - val_loss: 1.6783 - val_acc: 0.8628\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.4892 - acc: 0.8628\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0115 - acc: 0.9962 - val_loss: 1.4892 - val_acc: 0.8628\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0043 - acc: 0.8714\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0039 - acc: 0.9993 - val_loss: 2.0043 - val_acc: 0.8714\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.1959 - acc: 0.8800\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0341 - acc: 0.9913 - val_loss: 1.1959 - val_acc: 0.8800\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.4455 - acc: 0.7467\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 2.4455 - val_acc: 0.7467\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8638 - acc: 0.8589\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0072 - acc: 0.9977 - val_loss: 1.8638 - val_acc: 0.8589\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.6556 - acc: 0.8488\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0156 - acc: 0.9966 - val_loss: 1.6556 - val_acc: 0.8488\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9858 - acc: 0.8737\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0173 - acc: 0.9957 - val_loss: 1.9858 - val_acc: 0.8737\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 1s 26ms/step - loss: 1.7863 - acc: 0.8316\n",
            "256/256 [==============================] - 9s 35ms/step - loss: 0.0096 - acc: 0.9973 - val_loss: 1.7863 - val_acc: 0.8316\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9495 - acc: 0.8691\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0121 - acc: 0.9974 - val_loss: 1.9495 - val_acc: 0.8691\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8948 - acc: 0.8722\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 1.8948 - val_acc: 0.8722\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9453 - acc: 0.8737\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0079 - acc: 0.9978 - val_loss: 1.9453 - val_acc: 0.8737\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8873 - acc: 0.8620\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0072 - acc: 0.9975 - val_loss: 1.8873 - val_acc: 0.8620\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7009 - acc: 0.8761\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 1.7009 - val_acc: 0.8761\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8539 - acc: 0.8691\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0070 - acc: 0.9974 - val_loss: 1.8539 - val_acc: 0.8691\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.2240 - acc: 0.8262\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0046 - acc: 0.9984 - val_loss: 2.2240 - val_acc: 0.8262\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.1301 - acc: 0.8722\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0106 - acc: 0.9958 - val_loss: 2.1301 - val_acc: 0.8722\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.6928 - acc: 0.8683\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0059 - acc: 0.9982 - val_loss: 1.6928 - val_acc: 0.8683\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.8772 - acc: 0.8714\n",
            "256/256 [==============================] - 10s 38ms/step - loss: 0.0570 - acc: 0.9837 - val_loss: 1.8772 - val_acc: 0.8714\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.6414 - acc: 0.8511\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0781 - acc: 0.9810 - val_loss: 1.6414 - val_acc: 0.8511\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.5096 - acc: 0.8652\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0251 - acc: 0.9958 - val_loss: 1.5096 - val_acc: 0.8652\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9334 - acc: 0.8722\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0200 - acc: 0.9945 - val_loss: 1.9334 - val_acc: 0.8722\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.5223 - acc: 0.8589\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0222 - acc: 0.9935 - val_loss: 1.5223 - val_acc: 0.8589\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9689 - acc: 0.8706\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0060 - acc: 0.9980 - val_loss: 1.9689 - val_acc: 0.8706\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.8830 - acc: 0.8753\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0085 - acc: 0.9979 - val_loss: 1.8830 - val_acc: 0.8753\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.6420 - acc: 0.8745\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0063 - acc: 0.9985 - val_loss: 1.6420 - val_acc: 0.8745\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9553 - acc: 0.8636\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 1.9553 - val_acc: 0.8636\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.9743 - acc: 0.8722\n",
            "256/256 [==============================] - 9s 37ms/step - loss: 0.0071 - acc: 0.9974 - val_loss: 1.9743 - val_acc: 0.8722\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7823 - acc: 0.8745\n",
            "256/256 [==============================] - 9s 34ms/step - loss: 0.0415 - acc: 0.9934 - val_loss: 1.7823 - val_acc: 0.8745\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8016 - acc: 0.8753\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 1.8016 - val_acc: 0.8753\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8495 - acc: 0.8730\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0366 - acc: 0.9984 - val_loss: 1.8495 - val_acc: 0.8730\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.7915 - acc: 0.8698\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0144 - acc: 0.9973 - val_loss: 1.7915 - val_acc: 0.8698\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.6413 - acc: 0.8613\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0122 - acc: 0.9972 - val_loss: 1.6413 - val_acc: 0.8613\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8619 - acc: 0.8722\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0050 - acc: 0.9983 - val_loss: 1.8619 - val_acc: 0.8722\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 2.0156 - acc: 0.8620\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0029 - acc: 0.9989 - val_loss: 2.0156 - val_acc: 0.8620\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0162 - acc: 0.8636\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0060 - acc: 0.9984 - val_loss: 2.0162 - val_acc: 0.8636\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 0.9487 - acc: 0.8683\n",
            "256/256 [==============================] - 9s 34ms/step - loss: 0.0408 - acc: 0.9909 - val_loss: 0.9487 - val_acc: 0.8683\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7116 - acc: 0.8675\n",
            "256/256 [==============================] - 9s 37ms/step - loss: 0.0760 - acc: 0.9830 - val_loss: 1.7116 - val_acc: 0.8675\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9423 - acc: 0.8465\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0185 - acc: 0.9949 - val_loss: 1.9423 - val_acc: 0.8465\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9546 - acc: 0.8636\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0069 - acc: 0.9978 - val_loss: 1.9546 - val_acc: 0.8636\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7737 - acc: 0.8753\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0101 - acc: 0.9969 - val_loss: 1.7737 - val_acc: 0.8753\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9216 - acc: 0.8683\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0040 - acc: 0.9989 - val_loss: 1.9216 - val_acc: 0.8683\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8906 - acc: 0.8714\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0182 - acc: 0.9952 - val_loss: 1.8906 - val_acc: 0.8714\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8793 - acc: 0.8722\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0068 - acc: 0.9984 - val_loss: 1.8793 - val_acc: 0.8722\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8581 - acc: 0.8589\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0438 - acc: 0.9893 - val_loss: 1.8581 - val_acc: 0.8589\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.5999 - acc: 0.8410\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0246 - acc: 0.9933 - val_loss: 1.5999 - val_acc: 0.8410\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.9267 - acc: 0.8581\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0156 - acc: 0.9964 - val_loss: 1.9267 - val_acc: 0.8581\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7897 - acc: 0.8675\n",
            "256/256 [==============================] - 9s 34ms/step - loss: 0.0062 - acc: 0.9984 - val_loss: 1.7897 - val_acc: 0.8675\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9595 - acc: 0.8449\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 1.9595 - val_acc: 0.8449\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.8576 - acc: 0.8675\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0307 - acc: 0.9944 - val_loss: 1.8576 - val_acc: 0.8675\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.9083 - acc: 0.8535\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0497 - acc: 0.9917 - val_loss: 1.9083 - val_acc: 0.8535\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.8412 - acc: 0.8714\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0135 - acc: 0.9961 - val_loss: 1.8412 - val_acc: 0.8714\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.5158 - acc: 0.8504\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0056 - acc: 0.9980 - val_loss: 1.5158 - val_acc: 0.8504\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.5971 - acc: 0.8644\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 1.5971 - val_acc: 0.8644\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 1s 22ms/step - loss: 1.9285 - acc: 0.8691\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0309 - acc: 0.9936 - val_loss: 1.9285 - val_acc: 0.8691\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.9609 - acc: 0.8714\n",
            "256/256 [==============================] - 10s 37ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 1.9609 - val_acc: 0.8714\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9662 - acc: 0.8581\n",
            "256/256 [==============================] - 9s 37ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 1.9662 - val_acc: 0.8581\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8030 - acc: 0.8246\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0110 - acc: 0.9989 - val_loss: 1.8030 - val_acc: 0.8246\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8838 - acc: 0.8714\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0232 - acc: 0.9936 - val_loss: 1.8838 - val_acc: 0.8714\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9230 - acc: 0.8675\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0053 - acc: 0.9982 - val_loss: 1.9230 - val_acc: 0.8675\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.9213 - acc: 0.8706\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0089 - acc: 0.9968 - val_loss: 1.9213 - val_acc: 0.8706\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 1s 22ms/step - loss: 1.9666 - acc: 0.8566\n",
            "256/256 [==============================] - 10s 39ms/step - loss: 0.0457 - acc: 0.9945 - val_loss: 1.9666 - val_acc: 0.8566\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0038 - acc: 0.8753\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0050 - acc: 0.9982 - val_loss: 2.0038 - val_acc: 0.8753\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0211 - acc: 0.8714\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0123 - acc: 0.9971 - val_loss: 2.0211 - val_acc: 0.8714\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 1s 23ms/step - loss: 1.9275 - acc: 0.8433\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0127 - acc: 0.9961 - val_loss: 1.9275 - val_acc: 0.8433\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 1s 24ms/step - loss: 1.9917 - acc: 0.8636\n",
            "256/256 [==============================] - 10s 38ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 1.9917 - val_acc: 0.8636\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.9697 - acc: 0.8644\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0044 - acc: 0.9984 - val_loss: 1.9697 - val_acc: 0.8644\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0672 - acc: 0.8519\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0047 - acc: 0.9990 - val_loss: 2.0672 - val_acc: 0.8519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d5TVoRE8tNea",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Even bigger"
      ]
    },
    {
      "metadata": {
        "id": "DPJpdD04tQSR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_conv_2 = tf.keras.Sequential([\n",
        "    \n",
        "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), input_shape = (60,60,3), padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(),   \n",
        "    \n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(), \n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)), \n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(), \n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(), \n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),  \n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(), \n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.BatchNormalization(), \n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),  \n",
        "    \n",
        "    tf.keras.layers.Flatten(), \n",
        "    \n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate = 0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate = 0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate = 0.25),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "model_conv_2.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cm7Mz7PTtYn8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3731
        },
        "outputId": "ea315c85-efeb-4bc5-8cb3-8b9490835324"
      },
      "cell_type": "code",
      "source": [
        "history_conv_2 = model_conv_1.fit_generator(train_generator, validation_data= val_generator, epochs = 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 1s 22ms/step - loss: 1.3814 - acc: 0.8737\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0269 - acc: 0.9938 - val_loss: 1.3814 - val_acc: 0.8737\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8202 - acc: 0.8784\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0123 - acc: 0.9969 - val_loss: 1.8202 - val_acc: 0.8784\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.8930 - acc: 0.8589\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0174 - acc: 0.9963 - val_loss: 1.8930 - val_acc: 0.8589\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.1924 - acc: 0.8457\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0467 - acc: 0.9941 - val_loss: 1.1924 - val_acc: 0.8457\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9406 - acc: 0.8659\n",
            "256/256 [==============================] - 9s 33ms/step - loss: 0.0162 - acc: 0.9958 - val_loss: 1.9406 - val_acc: 0.8659\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0328 - acc: 0.8683\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0057 - acc: 0.9977 - val_loss: 2.0328 - val_acc: 0.8683\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9774 - acc: 0.8644\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0245 - acc: 0.9952 - val_loss: 1.9774 - val_acc: 0.8644\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9806 - acc: 0.8722\n",
            "256/256 [==============================] - 9s 33ms/step - loss: 0.0068 - acc: 0.9987 - val_loss: 1.9806 - val_acc: 0.8722\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.7850 - acc: 0.8691\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0191 - acc: 0.9955 - val_loss: 1.7850 - val_acc: 0.8691\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9704 - acc: 0.8714\n",
            "256/256 [==============================] - 9s 34ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 1.9704 - val_acc: 0.8714\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7889 - acc: 0.8714\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 1.7889 - val_acc: 0.8714\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 2.0046 - acc: 0.8613\n",
            "256/256 [==============================] - 9s 34ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 2.0046 - val_acc: 0.8613\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0259 - acc: 0.8730\n",
            "256/256 [==============================] - 10s 38ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 2.0259 - val_acc: 0.8730\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0258 - acc: 0.8698\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 6.6150e-04 - acc: 0.9998 - val_loss: 2.0258 - val_acc: 0.8698\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.5445 - acc: 0.8613\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0266 - acc: 0.9925 - val_loss: 1.5445 - val_acc: 0.8613\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9194 - acc: 0.8090\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0092 - acc: 0.9980 - val_loss: 1.9194 - val_acc: 0.8090\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 1s 23ms/step - loss: 1.1487 - acc: 0.8293\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0465 - acc: 0.9945 - val_loss: 1.1487 - val_acc: 0.8293\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9620 - acc: 0.8589\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0146 - acc: 0.9949 - val_loss: 1.9620 - val_acc: 0.8589\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7291 - acc: 0.8628\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0264 - acc: 0.9939 - val_loss: 1.7291 - val_acc: 0.8628\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0821 - acc: 0.8613\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 2.0821 - val_acc: 0.8613\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9602 - acc: 0.8628\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0056 - acc: 0.9980 - val_loss: 1.9602 - val_acc: 0.8628\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.9184 - acc: 0.8589\n",
            "256/256 [==============================] - 10s 38ms/step - loss: 0.0478 - acc: 0.9944 - val_loss: 1.9184 - val_acc: 0.8589\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 1s 22ms/step - loss: 1.8211 - acc: 0.8348\n",
            "256/256 [==============================] - 9s 34ms/step - loss: 0.0129 - acc: 0.9963 - val_loss: 1.8211 - val_acc: 0.8348\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.8266 - acc: 0.8558\n",
            "256/256 [==============================] - 10s 38ms/step - loss: 0.0095 - acc: 0.9973 - val_loss: 1.8266 - val_acc: 0.8558\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9222 - acc: 0.8628\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 1.9222 - val_acc: 0.8628\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8938 - acc: 0.8589\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0050 - acc: 0.9989 - val_loss: 1.8938 - val_acc: 0.8589\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 1s 20ms/step - loss: 1.8052 - acc: 0.8776\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0355 - acc: 0.9934 - val_loss: 1.8052 - val_acc: 0.8776\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9555 - acc: 0.8620\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0070 - acc: 0.9974 - val_loss: 1.9555 - val_acc: 0.8620\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9656 - acc: 0.8737\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 1.9656 - val_acc: 0.8737\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8533 - acc: 0.8488\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0099 - acc: 0.9985 - val_loss: 1.8533 - val_acc: 0.8488\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.9734 - acc: 0.8722\n",
            "256/256 [==============================] - 9s 37ms/step - loss: 0.0057 - acc: 0.9989 - val_loss: 1.9734 - val_acc: 0.8722\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8790 - acc: 0.8636\n",
            "256/256 [==============================] - 9s 34ms/step - loss: 0.0312 - acc: 0.9934 - val_loss: 1.8790 - val_acc: 0.8636\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0036 - acc: 0.8667\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 8.8543e-04 - acc: 0.9999 - val_loss: 2.0036 - val_acc: 0.8667\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 1s 22ms/step - loss: 1.9467 - acc: 0.8511\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0084 - acc: 0.9983 - val_loss: 1.9467 - val_acc: 0.8511\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9283 - acc: 0.8745\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0040 - acc: 0.9988 - val_loss: 1.9283 - val_acc: 0.8745\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 5.0901 - acc: 0.4248\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0383 - acc: 0.9966 - val_loss: 5.0901 - val_acc: 0.4248\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8607 - acc: 0.8730\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0193 - acc: 0.9942 - val_loss: 1.8607 - val_acc: 0.8730\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9645 - acc: 0.8652\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 1.9645 - val_acc: 0.8652\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8911 - acc: 0.8753\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 1.8911 - val_acc: 0.8753\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 2.0292 - acc: 0.8667\n",
            "256/256 [==============================] - 9s 35ms/step - loss: 0.0152 - acc: 0.9967 - val_loss: 2.0292 - val_acc: 0.8667\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8041 - acc: 0.8636\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0061 - acc: 0.9975 - val_loss: 1.8041 - val_acc: 0.8636\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0671 - acc: 0.8628\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 2.0671 - val_acc: 0.8628\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9888 - acc: 0.8628\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0068 - acc: 0.9989 - val_loss: 1.9888 - val_acc: 0.8628\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9430 - acc: 0.8472\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0059 - acc: 0.9979 - val_loss: 1.9430 - val_acc: 0.8472\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.6402 - acc: 0.8667\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0019 - acc: 0.9993 - val_loss: 1.6402 - val_acc: 0.8667\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9500 - acc: 0.8597\n",
            "256/256 [==============================] - 8s 32ms/step - loss: 0.0047 - acc: 0.9993 - val_loss: 1.9500 - val_acc: 0.8597\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9622 - acc: 0.8613\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0382 - acc: 0.9941 - val_loss: 1.9622 - val_acc: 0.8613\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9500 - acc: 0.8652\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0053 - acc: 0.9982 - val_loss: 1.9500 - val_acc: 0.8652\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.1416 - acc: 0.8535\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0044 - acc: 0.9991 - val_loss: 2.1416 - val_acc: 0.8535\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.9831 - acc: 0.8691\n",
            "256/256 [==============================] - 10s 38ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 1.9831 - val_acc: 0.8691\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9985 - acc: 0.8745\n",
            "256/256 [==============================] - 9s 33ms/step - loss: 0.0019 - acc: 0.9993 - val_loss: 1.9985 - val_acc: 0.8745\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 2.2096 - acc: 0.8465\n",
            "256/256 [==============================] - 9s 34ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 2.2096 - val_acc: 0.8465\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0370 - acc: 0.8558\n",
            "256/256 [==============================] - 9s 35ms/step - loss: 0.0031 - acc: 0.9987 - val_loss: 2.0370 - val_acc: 0.8558\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9505 - acc: 0.8488\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0131 - acc: 0.9963 - val_loss: 1.9505 - val_acc: 0.8488\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 2.0516 - acc: 0.8628\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0322 - acc: 0.9993 - val_loss: 2.0516 - val_acc: 0.8628\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.5779 - acc: 0.8730\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0331 - acc: 0.9920 - val_loss: 1.5779 - val_acc: 0.8730\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9733 - acc: 0.8675\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0025 - acc: 0.9990 - val_loss: 1.9733 - val_acc: 0.8675\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7805 - acc: 0.8737\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 1.7805 - val_acc: 0.8737\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.6589 - acc: 0.8667\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 1.6589 - val_acc: 0.8667\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.6406 - acc: 0.8698\n",
            "256/256 [==============================] - 10s 39ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 1.6406 - val_acc: 0.8698\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9171 - acc: 0.8753\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 1.9171 - val_acc: 0.8753\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.5895 - acc: 0.8613\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0145 - acc: 0.9963 - val_loss: 1.5895 - val_acc: 0.8613\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.8754 - acc: 0.8644\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0213 - acc: 0.9944 - val_loss: 1.8754 - val_acc: 0.8644\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9322 - acc: 0.8644\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0078 - acc: 0.9987 - val_loss: 1.9322 - val_acc: 0.8644\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9987 - acc: 0.8675\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 1.9987 - val_acc: 0.8675\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.2628 - acc: 0.8496\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0362 - acc: 0.9922 - val_loss: 1.2628 - val_acc: 0.8496\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.9791 - acc: 0.8698\n",
            "256/256 [==============================] - 8s 33ms/step - loss: 0.0141 - acc: 0.9956 - val_loss: 1.9791 - val_acc: 0.8698\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 1s 25ms/step - loss: 1.2802 - acc: 0.8613\n",
            "256/256 [==============================] - 9s 35ms/step - loss: 0.0158 - acc: 0.9963 - val_loss: 1.2802 - val_acc: 0.8613\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.7735 - acc: 0.8652\n",
            "256/256 [==============================] - 9s 36ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 1.7735 - val_acc: 0.8652\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 1s 21ms/step - loss: 1.6004 - acc: 0.8706\n",
            "256/256 [==============================] - 10s 39ms/step - loss: 0.0565 - acc: 0.9931 - val_loss: 1.6004 - val_acc: 0.8706\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 1s 22ms/step - loss: 1.8566 - acc: 0.8675\n",
            "256/256 [==============================] - 9s 33ms/step - loss: 0.0066 - acc: 0.9983 - val_loss: 1.8566 - val_acc: 0.8675\n",
            "Epoch 72/100\n",
            "143/256 [===============>..............] - ETA: 3s - loss: 0.0053 - acc: 0.9980"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}